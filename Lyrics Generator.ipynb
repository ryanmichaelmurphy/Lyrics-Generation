{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Music Bot 3000",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMfcpiYeoGN3"
      },
      "source": [
        "This program scrapes a band or artists lyrics from Genius and uses these lyrics generate lyrics using Markov chains and to train a neural network to write lyrics in the style of the artist."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBkpRgBCBS2_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de94dffb-54b3-433f-8a8c-436dc0e0f792"
      },
      "source": [
        "!pip3 install git+git://github.com/minimaxir/textgenrnn.git#v1.5.0\n",
        "!pip install lyricsgenius\n",
        "\n",
        "from lyricsgenius import Genius\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "from tensorflow.python.keras.utils.multi_gpu_utils import multi_gpu_model\n",
        "from textgenrnn import textgenrnn\n",
        "from datetime import datetime\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+git://github.com/minimaxir/textgenrnn.git#v1.5.0\n",
            "  Cloning git://github.com/minimaxir/textgenrnn.git to /tmp/pip-req-build-gv4cvumt\n",
            "  Running command git clone -q git://github.com/minimaxir/textgenrnn.git /tmp/pip-req-build-gv4cvumt\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from textgenrnn==2.0.0) (3.1.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from textgenrnn==2.0.0) (0.22.2.post1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from textgenrnn==2.0.0) (4.62.0)\n",
            "Requirement already satisfied: tensorflow>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from textgenrnn==2.0.0) (2.6.0)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->textgenrnn==2.0.0) (1.15.0)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->textgenrnn==2.0.0) (0.4.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->textgenrnn==2.0.0) (1.12.1)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->textgenrnn==2.0.0) (3.17.3)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->textgenrnn==2.0.0) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-estimator~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->textgenrnn==2.0.0) (2.6.0)\n",
            "Requirement already satisfied: clang~=5.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->textgenrnn==2.0.0) (5.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->textgenrnn==2.0.0) (1.6.3)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->textgenrnn==2.0.0) (1.1.2)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->textgenrnn==2.0.0) (0.12.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->textgenrnn==2.0.0) (1.1.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.37.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->textgenrnn==2.0.0) (1.39.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->textgenrnn==2.0.0) (1.12)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->textgenrnn==2.0.0) (1.19.5)\n",
            "Requirement already satisfied: keras~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->textgenrnn==2.0.0) (2.6.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->textgenrnn==2.0.0) (2.6.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->textgenrnn==2.0.0) (0.2.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->textgenrnn==2.0.0) (0.37.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->textgenrnn==2.0.0) (3.7.4.3)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->textgenrnn==2.0.0) (1.5.2)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.1.0->textgenrnn==2.0.0) (1.34.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.1.0->textgenrnn==2.0.0) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.1.0->textgenrnn==2.0.0) (1.8.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.1.0->textgenrnn==2.0.0) (0.4.5)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.1.0->textgenrnn==2.0.0) (3.3.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.1.0->textgenrnn==2.0.0) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.1.0->textgenrnn==2.0.0) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.1.0->textgenrnn==2.0.0) (57.4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow>=2.1.0->textgenrnn==2.0.0) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow>=2.1.0->textgenrnn==2.0.0) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow>=2.1.0->textgenrnn==2.0.0) (4.2.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.1.0->textgenrnn==2.0.0) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.1.0->textgenrnn==2.0.0) (4.6.4)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow>=2.1.0->textgenrnn==2.0.0) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow>=2.1.0->textgenrnn==2.0.0) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow>=2.1.0->textgenrnn==2.0.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow>=2.1.0->textgenrnn==2.0.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow>=2.1.0->textgenrnn==2.0.0) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.1.0->textgenrnn==2.0.0) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.1.0->textgenrnn==2.0.0) (3.5.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->textgenrnn==2.0.0) (1.0.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->textgenrnn==2.0.0) (1.4.1)\n",
            "Requirement already satisfied: lyricsgenius in /usr/local/lib/python3.7/dist-packages (3.0.1)\n",
            "Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from lyricsgenius) (2.23.0)\n",
            "Requirement already satisfied: beautifulsoup4>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from lyricsgenius) (4.6.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->lyricsgenius) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->lyricsgenius) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->lyricsgenius) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->lyricsgenius) (1.24.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0x3xaqJ6DG_H"
      },
      "source": [
        "This section prompts a user to enter a band or artist name and scrapes all the lyrics from that artist from the website Genius using the lyricsgenius library. [note: It takes a few minutes to scrape this content.]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G54GUSUfkmRp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "869aa40c-ff93-4269-fc3e-e5d0eb9ef627"
      },
      "source": [
        "artist_name = str(input(\"Enter the artists name:\")) \n",
        "\n",
        "genius = Genius('2fThypCYHhkShgZ8ph2qpyaqxVgi5edTgUh4P06_q7AuS5UC9zs7Azdo_rjY-X1U')\n",
        "\n",
        "genius.verbose = False # Turn off status messages\n",
        "genius.remove_section_headers = True # Remove section headers (e.g. [Chorus]) from lyrics when searching\n",
        "genius.skip_non_songs = False # Include hits thought to be non-songs (e.g. track lists)\n",
        "genius.excluded_terms = [\"(Remix)\", \"(Live)\"] # Exclude songs with these words in their title\n",
        "\n",
        "artist = genius.search_artist(artist_name, sort=\"title\")\n",
        "\n",
        "lyrics = artist.save_lyrics(filename='Lyrics_' + artist_name.replace(\" \", \"\"), extension=\"txt\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the artists name:The Magnetic Fields\n",
            "Wrote Lyrics_TheMagneticFields.txt.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4cITpyBk19y"
      },
      "source": [
        "lyricStr = open(\"Lyrics_\" + artist_name.replace(\" \", \"\") + \".txt\")\n",
        "\n",
        "lyricStr1 = lyricStr.read().replace(\"EmbedShare URLCopyEmbedCopy\", \" \")\n",
        "lyricStr2 = lyricStr1.replace(\"\\n\", \" \")\n",
        "\n",
        "with open(\"Lyrics_\" + artist_name.replace(\" \", \"\") + \"_Clean.txt\", \"w\") as text_file:\n",
        "    text_file.write(lyricStr2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wskcnpKbCWpO"
      },
      "source": [
        "This section generates lyrics using Markov chains. It starts with a random word and makes a random choice of the next word influenced by the probabilities of a word appearing next in the dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HiSk6g8YBblB",
        "outputId": "97d9b5d2-43d8-4914-8fb2-b68849551f9e"
      },
      "source": [
        "def generateLyrics(inspiration, words):\n",
        "    corpus = inspiration.split()\n",
        "\n",
        "    def make_pairs(corpus):\n",
        "        for i in range(len(corpus)-1):\n",
        "            yield (corpus[i], corpus[i+1])\n",
        "            \n",
        "    pairs = make_pairs(corpus)\n",
        "\n",
        "    word_dict = {}\n",
        "\n",
        "    for word_1, word_2 in pairs:\n",
        "        if word_1 in word_dict.keys():\n",
        "            word_dict[word_1].append(word_2)\n",
        "        else:\n",
        "            word_dict[word_1] = [word_2]\n",
        "     \n",
        "    first_word = np.random.choice(corpus)\n",
        "\n",
        "    while first_word.islower():\n",
        "        first_word = np.random.choice(corpus)\n",
        "\n",
        "    chain = [first_word]\n",
        "\n",
        "    n_words = words\n",
        "\n",
        "    for i in range(n_words):\n",
        "        chain.append(np.random.choice(word_dict[chain[-1]]))\n",
        "    \n",
        "    mc_lyrics = \" \"\n",
        "    mc_lyrics = mc_lyrics.join(chain)\n",
        "    print(mc_lyrics)\n",
        "\n",
        "generateLyrics(lyricStr1, 100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "But let's make you were young, and abandoned, and Ted And nothing else you let go 'round just for a funny And now I saw you won't get too And nothing I think I want to do It's just stand there, we lived here Your face all I never give our marriage certificate And men First time is done Make a dancing in darkness without the children drowned Now children, listen well and baby Although my name again I've always got strange for a wealthy man grow Plant white In the air You used that make it still getting up with\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wXB05bPDYxS"
      },
      "source": [
        "This section uses the textgenrnn library, a recursive neural network, to generate lyrics. \n",
        "\n",
        "See the demo notebook (https://github.com/minimaxir/textgenrnn/blob/master/docs/textgenrnn-demo.ipynb) for more information about the parameters in the cell below.\n",
        "\n",
        "[note: Depending on the parameters chosen, it can take anywhere from a few minutes to a few hours to train the neural network and generate lyrics.]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8wSlgXoDPCR"
      },
      "source": [
        "model_cfg = {\n",
        "    'word_level': True,   # set to True if want to train a word-level model (requires more data and smaller max_length)\n",
        "    'rnn_size': 128,   # number of LSTM cells of each layer (128/256 recommended)\n",
        "    'rnn_layers': 4,   # number of LSTM layers (>=2 recommended)\n",
        "    'rnn_bidirectional': True,   # consider text both forwards and backward, can give a training boost\n",
        "    'max_length': 2,   # number of tokens to consider before predicting the next (20-40 for characters, 5-10 for words recommended)\n",
        "    'max_words': 1000000,   # maximum number of words to model; the rest will be ignored (word-level model only)\n",
        "}\n",
        "\n",
        "train_cfg = {\n",
        "    'line_delimited': False,   # set to True if each text has its own line in the source file\n",
        "    'num_epochs': 20,   # set higher to train the model for longer\n",
        "    'gen_epochs': 20,   # generates sample text from model after given number of epochs\n",
        "    'train_size': 0.8,   # proportion of input data to train on: setting < 1.0 limits model from learning perfectly\n",
        "    'dropout': 0.0,   # ignore a random proportion of source tokens each epoch, allowing model to generalize better\n",
        "    'validation': True,   # If train__size < 1.0, test on holdout dataset; will make overall training slower\n",
        "    'is_csv': False   # set to True if file is a CSV exported from Excel/BigQuery/pandas\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OFnPCLADfll"
      },
      "source": [
        "file_name = \"Lyrics_\"+ artist_name.replace(\" \", \"\") + \"_Clean.txt\"\n",
        "model_name = artist_name.replace(\" \", \"\") + '_Output'   # change to set file name of resulting trained models/texts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdpZQXknFNY3"
      },
      "source": [
        "The next cell will start the actual training. And thanks to the power of Keras's CuDNN layers, training is super-fast when compared to CPU training on a local machine!\n",
        "\n",
        "Ideally, you want a training loss less than `1.0` in order for the model to create sensible text consistently."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeXshJM-Cuaf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ab1503e-818f-4ff0-9519-1c407692d04c"
      },
      "source": [
        "textgen = textgenrnn(name=model_name)\n",
        "\n",
        "train_function = textgen.train_from_file if train_cfg['line_delimited'] else textgen.train_from_largetext_file\n",
        "\n",
        "train_function(\n",
        "    file_path=file_name,\n",
        "    new_model=True,\n",
        "    num_epochs=train_cfg['num_epochs'],\n",
        "    gen_epochs=train_cfg['gen_epochs'],\n",
        "    batch_size=1024,\n",
        "    train_size=train_cfg['train_size'],\n",
        "    dropout=train_cfg['dropout'],\n",
        "    validation=train_cfg['validation'],\n",
        "    is_csv=train_cfg['is_csv'],\n",
        "    rnn_layers=model_cfg['rnn_layers'],\n",
        "    rnn_size=model_cfg['rnn_size'],\n",
        "    rnn_bidirectional=model_cfg['rnn_bidirectional'],\n",
        "    max_length=model_cfg['max_length'],\n",
        "    dim_embeddings=100,\n",
        "    word_level=model_cfg['word_level'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training new model w/ 4-layer, 128-cell Bidirectional LSTMs\n",
            "Training on 40,113 word sequences.\n",
            "Epoch 1/20\n",
            "39/39 [==============================] - 74s 2s/step - loss: 6.8809 - val_loss: 6.2319\n",
            "Epoch 2/20\n",
            "39/39 [==============================] - 57s 1s/step - loss: 5.7664 - val_loss: 5.7987\n",
            "Epoch 3/20\n",
            "39/39 [==============================] - 57s 1s/step - loss: 5.0983 - val_loss: 5.4214\n",
            "Epoch 4/20\n",
            "39/39 [==============================] - 57s 1s/step - loss: 4.4434 - val_loss: 5.3035\n",
            "Epoch 5/20\n",
            "39/39 [==============================] - 57s 1s/step - loss: 3.8638 - val_loss: 5.2264\n",
            "Epoch 6/20\n",
            "39/39 [==============================] - 58s 1s/step - loss: 3.3182 - val_loss: 5.3126\n",
            "Epoch 7/20\n",
            "39/39 [==============================] - 57s 1s/step - loss: 2.8151 - val_loss: 5.4460\n",
            "Epoch 8/20\n",
            "39/39 [==============================] - 56s 1s/step - loss: 2.4596 - val_loss: 5.5310\n",
            "Epoch 9/20\n",
            "39/39 [==============================] - 57s 1s/step - loss: 2.1847 - val_loss: 5.5598\n",
            "Epoch 10/20\n",
            "39/39 [==============================] - 57s 1s/step - loss: 1.9720 - val_loss: 5.6851\n",
            "Epoch 11/20\n",
            "39/39 [==============================] - 58s 1s/step - loss: 1.8061 - val_loss: 5.6620\n",
            "Epoch 12/20\n",
            "39/39 [==============================] - 57s 1s/step - loss: 1.6319 - val_loss: 5.8027\n",
            "Epoch 13/20\n",
            "39/39 [==============================] - 57s 1s/step - loss: 1.5333 - val_loss: 5.9196\n",
            "Epoch 14/20\n",
            "39/39 [==============================] - 57s 1s/step - loss: 1.4623 - val_loss: 5.8794\n",
            "Epoch 15/20\n",
            "39/39 [==============================] - 57s 1s/step - loss: 1.3840 - val_loss: 5.9760\n",
            "Epoch 16/20\n",
            "39/39 [==============================] - 56s 1s/step - loss: 1.3302 - val_loss: 5.9468\n",
            "Epoch 17/20\n",
            "39/39 [==============================] - 56s 1s/step - loss: 1.2662 - val_loss: 6.0623\n",
            "Epoch 18/20\n",
            "39/39 [==============================] - 57s 1s/step - loss: 1.2029 - val_loss: 6.1520\n",
            "Epoch 19/20\n",
            "39/39 [==============================] - 57s 1s/step - loss: 1.1823 - val_loss: 6.0773\n",
            "Epoch 20/20\n",
            "39/39 [==============================] - 56s 1s/step - loss: 1.1505 - val_loss: 6.1746\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "t believe you i can t spend my life with you infatuated with you i can t spend my life with you infatuated with you infatuated with you infatuated with you infatuated with you infatuated with you infatuated with you infatuated with you i can t spend my life with you i can t bring her back bring her back bring her back bring her back bring her back bring her back bring her back bring her back bring her back bring her back bring her back bring her back bring her back bring her back bring her back bring her back bring her back bring her back bring her back bring her back bring her back bring her back bring her back bring her back bring her back bring her back bring her back bring her back bring her back bring her back bring her back bring her back bring her back bring her back bring her back bring her back bring her back bring her back bring her back bring her back bring her back bring her back bring her back bring her back bring her back bring her back bring her back bring her back bring her back bring her back bring her back bring her back bring her back bring her back bring her back bring her back bring her back bring her back bring her back bring her back bring her back bring her back bring her back bring her back bring her back bring her back bring her back bring her back bring her back bring her back bring her back bring her back bring her back bring her back bring her back bring her back bring her back bring her back bring her back bring her back bring her back bring her back\n",
            "\n",
            "know what to say i could say i could say i could say i could say i could say i could say i could say i could keep i thought you were my boyfriend i thought you were my boyfriend i thought you were my boyfriend i thought you were my boyfriend i thought you were my boyfriend i thought you were my boyfriend i thought you were my boyfriend i thought you were my boyfriend i thought you were my boyfriend i thought you were my boyfriend i thought you were my boyfriend i thought you were my boyfriend i thought you were my boyfriend i thought you were my boyfriend i thought you were my boyfriend i thought you were my boyfriend i thought you were my boyfriend i thought you were my boyfriend i thought you were my boyfriend i thought you were my boyfriend i thought you were my boyfriend i thought you were my boyfriend i thought you were my boyfriend i thought you were my boyfriend i thought you were my boyfriend i thought you were my boyfriend i thought you were my boyfriend i thought you were my boyfriend i thought you were my boyfriend i thought you were my boyfriend i thought you were my boyfriend i thought you were my boyfriend i thought you were my boyfriend i thought you were my boyfriend i thought you were my boyfriend i thought you were my boyfriend i thought you were my boyfriend i thought you were my boyfriend i thought you were my boyfriend i thought you were my boyfriend i thought you were my boyfriend i thought you were my boyfriend i thought you were my boyfriend i thought you were my boyfriend i thought you were my boyfriend i thought\n",
            "\n",
            "t wanna stay around those trains and all the time and after all those quotes you never left me and the dog and the bugs all in two rooms with one bed so we slept on the dance goes on and on rainy nights when we walk hand in hand we will go and as long as you go dancing today oh what a price you pay when you were my boyfriend i thought you were my boyfriend i thought you were my boyfriend i thought you were my boyfriend i thought you were my boyfriend i thought you were my boyfriend i thought you were my boyfriend i thought you were my boyfriend love or not i be lonely in the snow white cottages as cute as cupid as love if there is nothing that i love you and i can t spend my life with you infatuated with you infatuated with you i can t spend my life with you infatuated with you i want to be a test on who have gone off their meds and away i could say i could say i could say i could say i could say i could write a song about the way you say good - night the way you say good - night the way you say good - night the way you say good - night the way you say good - night the way you say good - night the way you say good - night the way you say good - night the way you say good - night the way you say good - night the way you say good - night the way you say good - night the most important men in town oh if only you were my boyfriend i thought\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "t believe you i can t forget to feed them you want to be a scream song i wish i had a dream world where the lightning flowed the day i finally barnyard falling in and i can t take that kiss if you let go love is wrapped around my heart can break i can t spend my life with you infatuated with infatuation with your chihuahua in your mouth and worms in the snow white cottages i lived i like your old no - dad kill your soul and kill your soul and a cowboy hat everything she loved the moon needs poetry you need a new heart oh i think you are an alien being you write the third song and i can t bring her back to me you should know that someone is your sense of perfection and nothing matters when we walk hand in the sun i have a favorite bar where the colors are too intense and nothing is making sense there is nothing in this town just get out of your mind son you must be out of your height and swim your sea marry me she makes the best cup of coffee in tennessee i can t see what it means to be a topless waitress i want to be making the scene with me kid he said — laying his hands on country days i go when the wind needs the trees to blow in like the moon her back bring her back you can t bring her back bring her back bring her back bring her back bring her back bring her back bring her back bring her back you can t touch you anymore and what can i do it all day long oh i could say i could be my\n",
            "\n",
            "t wanna go for inches and some go for a ride wanna go for a girl like that but courtesans are not sweet and you can lose you love someone you can have it said happy beeping it said we were supposed to be a test on who have gone off their meds and away my trust me i know the solution love music and the bugs all in two rooms with one good characteristic you need a new heart oh i could keep i thought you were my boyfriend love or not i crazy i treated you like to beat you black and blue for all the umbrellas in london when the open road is closing in and the sun it will be twilight soon save a secret for the love of a warm summer day we can be heroes just for one day the boy the saddest story ever told so the sun i have a favorite bar we can be heroes we can be sure you will know you can never go back to me and the dog and the dog and the dog and the dog and the dog and the moon dancing in my dreams strange powers you were my boyfriend i thought i was made for love is lighter than air it rises through the night i dream of what was once and might have been cursed to tramp like soldiers through the years freely what to say goodbye and in missouri but after all those quotes you never said through every aeon much to hate you you tell me later that you know you can go back to new york i know your secret code we travel in the arms of my sweet - plan as the pavement whirls i hate you for all\n",
            "\n",
            "i could say i need to be the machine in your eyes i am not a teenager piss on your dreams muzzle your screams why i cry cry i die you die see my wife oh shadows of echoes of memories oh things you made a documentary concerning my friend shell was named for a laugh like a boa round your throat and you wanna go for a one night stand it at the dolls tea party where the lightning flowed you were my boyfriend i thought you were my boyfriend i thought you were my boyfriend i thought you were my boyfriend i thought you were my boyfriend i thought you were my boyfriend i thought you were the only boy in town for a week or two to go back to me and the bugs all in two rooms with one bed so we slept on the floor the ceiling fell in love with him i kept all my life with you infatuated with you baby you know how to love me that way so you know you can t spend my life with you i want to be like glue i thought you were my boyfriend love or not i crazy i treated you like god you were the only kind summer summer slowly and the cat and the bugs all in two drinks you were my boyfriend love or not i going through there is nothing i am mad as you put down on my neck the daddy of all the money in tokyo á go - go tokyo á go - go tokyo á go - go tokyo á go - go tokyo á go - go tokyo á go - go tokyo á go - go tokyo á go - go tokyo á go -\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "not find a little time my he said — laying his hands to this corner of the gods in an isolation booth when you love me or even not for all i want to know i looked all over town snow our love gone wrong and when the article was thine dramatic quotes a new look and sound like yes you think you can go back to jackson i can t believe you you know that i love you baby you could see this and they still care for the only sun it will be free somewhere into our dream world where can that sandy be where can that sandy be where can that sandy be down can see in your soul and in missouri we called ourselves the black and blue for all my friends you melted i was ten guys on whom prayed, to go dancing today oh what a time it was the bible train that took away her past it was some of it is no hope of falling in the middle of the earth in a font you just take it fade from view save a secret for the moon i have a beer cause they all danced till some still take me out of your own car i wish i had a dad paid my dues sea with who you say good - night and crying out my crying i said wanna bet the night tokyo á go - go tokyo á go - go times another songs and plays the toy piano move planets hips as he walked all alone and i we will go and as the dance goes on and i die you die you die but i might as love if when you leave me for a girl like that\n",
            "\n",
            "trying not to tell me fifty ways you have the roland sky as a gag i even went about the way you say good - night three - way three i suffered from petit mal epilepsy two big black balloon then watch it fade from view save a secret for the love of a sweet - man to keep you warm again lonely highway only to moles fate maybe so in the rain is coming to fly around the pool with strangers maybe wear some freakish fragrance fresh from france friend well i may sit in a field of sunflowers and there is no substitute cause she always loved the guy for you and me and the stars begin out of me gawking i should walk away and i can make me stay at last one man i read your manifestoes and your chaperone you you will wish i was made of wood well darling you may sleep in the sea and we never run to write you yet you must be out of dancing she ate whatever she felt like without a hint school but for good by just out of your money when nothing of love you do you still haunt me like you screw up for miles for me again i know you can flee in terror like everybody else does i rather just go dancing today oh what a price you pay in pain pay in your gaze be out of this town just get out of your tears play inside of your voice sends shivers up my spine and at your girlfriend first i could it shine on me like talking to pen in your hands shake then repair to your bar you at the dolls tea part we could be famous if you let\n",
            "\n",
            "it makes your words not if i knew i i can keep it up and without a hint new england town - five people died in the neon gas gets write an epic poem but for the company with a mama age not not really pine for you now that from now i confess yes yes yes yes yes yes yes yes yes yes yes yes yes yes yes yes yes yes yes yes yes yes yes yes yes yes yes yes yes yes yes yes yes yes yes yes yes yes yes yes yes yes yes yes yes yes yes yes yes yes yes yes yes yes yes yes yes yes yes yes yes yes yes yes yes yes yes yes yes yes yes yes yes yes yes yes yes yes yes yes yes yes yes yes yes yes yes yes yes i was yea high completely landing and i love you it he says come to full of fortune and fame but mostly those which one of us baby has a halo when it snows all night long at spin - the world the women sing their favorite song the moon is nearer you you can t find the breath to whisper goodbye whisper goodbye1 so faraway and so i twice am stuck affixed to this dive bar you can laugh aloud desert island where you never left and it would never end i thought i was a little time for the year alas and alack you just explode in a padded sawtooth a pretty girl i can t let it die but i can t forget to feed them scream i want to be getting along while you i will love you anymore i was paul romantic this is not for all the tea in china not\n",
            "\n"
          ]
        }
      ]
    }
  ]
}
